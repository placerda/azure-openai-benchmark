{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "log_folder = 'logs'\n",
    "\n",
    "# Function to clean and process each line to remove noise and keep only JSON content\n",
    "def preprocess_line(line):\n",
    "    try:\n",
    "        return json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "# Get a list of all log files in the 'log' directory\n",
    "log_files = [f for f in os.listdir(log_folder) if f.endswith('.log')]\n",
    "\n",
    "# Create a dictionary to hold all dataframes\n",
    "dfs = {}\n",
    "\n",
    "for file in log_files:\n",
    "    data = []\n",
    "    with open(f\"{log_folder}/{file}\", 'r') as f:\n",
    "        for line in f:\n",
    "            # Preprocess each line to remove noise\n",
    "            processed_line = preprocess_line(line)\n",
    "            if processed_line is not None:\n",
    "                data.append(processed_line)\n",
    "    \n",
    "    # Convert the processed data to a DataFrame\n",
    "    df = pd.json_normalize(data, sep='_')\n",
    "\n",
    "    # Remove the .log extension and use the filename as the key in the dictionary\n",
    "    dfs[file[:-4]] = df\n",
    "\n",
    "# Example of accessing a DataFrame (you can adjust based on your needs)\n",
    "# for key, df in dfs.items():\n",
    "    # print(f\"DataFrame for {key}:\")\n",
    "    # print(df.head())\n",
    "    \n",
    "\n",
    "# Print the number of test runs\n",
    "print(f\"Number of test runs: {len(dfs)}\")\n",
    "\n",
    "# Print the name of each test run\n",
    "for name in dfs.keys():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Test Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Increase the global font size\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# List of fields to plot\n",
    "fields = ['requests', 'failures']\n",
    "\n",
    "# Determine the number of rows and columns for the subplots\n",
    "nrows = len(fields)\n",
    "ncols = len(dfs)\n",
    "\n",
    "# Increase the height of each chart to 10 inches\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(2 * ncols * 6, nrows * 10))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Loop over each field, each dataframe, and each axes\n",
    "for i, field in enumerate(fields):\n",
    "    for j, (name, df) in enumerate(dfs.items()):\n",
    "        # Check if 'run_seconds' and field exist in df\n",
    "        if 'run_seconds' in df.columns and field in df.columns:\n",
    "            # Convert 'run_seconds' and field to numeric type and drop rows with NaN values\n",
    "            df['run_seconds'] = pd.to_numeric(df['run_seconds'], errors='coerce')\n",
    "            df[field] = pd.to_numeric(df[field], errors='coerce')\n",
    "            df = df.dropna(subset=['run_seconds', field])\n",
    "\n",
    "            # Create a line plot on each axes\n",
    "            if ncols > 1:\n",
    "                ax = axs[i, j]\n",
    "            else:\n",
    "                ax = axs[i]\n",
    "\n",
    "            ax.plot(df['run_seconds'], df[field])\n",
    "\n",
    "            # Truncate the name before the '=' character\n",
    "            truncated_name = name.split('_shape')[0]\n",
    "\n",
    "            # Set the title of the plot to the truncated name\n",
    "            ax.set_title(truncated_name)\n",
    "\n",
    "            # Set the labels for the x-axis and y-axis\n",
    "            ax.set_xlabel('run_seconds')\n",
    "            ax.set_ylabel(field)\n",
    "        else:\n",
    "            print(f\"'run_seconds' or '{field}' not found in DataFrame {name}\")\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Create a list to hold the last row of each DataFrame\n",
    "summary_data = []\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    # Check if the DataFrame is empty\n",
    "    if not df.empty:\n",
    "        # Get the last row of the DataFrame\n",
    "        last_row = df.iloc[-1:]\n",
    "        \n",
    "        # Add the name of the DataFrame as the first column\n",
    "        last_row.insert(0, 'DataFrame', name)\n",
    "    \n",
    "        # Append the last row to the summary_data list\n",
    "        summary_data.append(last_row)\n",
    "\n",
    "# Convert the list of last rows into a DataFrame\n",
    "summary_df = pd.concat(summary_data)\n",
    "\n",
    "# Print summary_df in a tabular format\n",
    "print('Execution Summary:')\n",
    "print(tabulate(summary_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def extract_stats_from_line(line):\n",
    "    match = re.search(r'Raw call stats:\\s*(\\[.*\\])', line)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        call_stats = json.loads(json_str)\n",
    "        \n",
    "        e2e_times = [entry['response_end_time'] - entry['request_start_time'] for entry in call_stats]\n",
    "        \n",
    "        max_e2e = round(max(e2e_times), 3)\n",
    "        min_e2e = round(min(e2e_times), 3)\n",
    "        avg_e2e = round(statistics.mean(e2e_times), 3)\n",
    "        variance_e2e = round(statistics.variance(e2e_times), 3)\n",
    "        std_dev_e2e = round(statistics.stdev(e2e_times), 3)\n",
    "        percentile_95_e2e = round(statistics.quantiles(e2e_times, n=100)[94], 3)\n",
    "\n",
    "        return {\n",
    "            \"max_e2e\": max_e2e,\n",
    "            \"min_e2e\": min_e2e,\n",
    "            \"avg_e2e\": avg_e2e,\n",
    "            \"variance_e2e\": variance_e2e,\n",
    "            \"std_dev_e2e\": std_dev_e2e,\n",
    "            \"percentile_95_e2e\": percentile_95_e2e,\n",
    "            \"e2e_times\": e2e_times\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get a list of all log files in the 'log' directory\n",
    "log_files = [f for f in os.listdir(log_folder) if f.endswith('.log')]\n",
    "\n",
    "for file in log_files:\n",
    "    data = []\n",
    "    with open(f\"{log_folder}/{file}\", 'r') as f:\n",
    "        for line in f:\n",
    "            stats = extract_stats_from_line(line)\n",
    "            if stats:\n",
    "                data.append(stats)\n",
    "                print(f\"Statistics for {file[:-4].split('_shape')[0]}:\")\n",
    "                print(f\"Max e2e time: {stats['max_e2e']}\")\n",
    "                print(f\"Min e2e time: {stats['min_e2e']}\")\n",
    "                print(f\"Average e2e time: {stats['avg_e2e']}\")\n",
    "                print(f\"Variance of e2e time: {stats['variance_e2e']}\")\n",
    "                print(f\"Standard deviation of e2e time: {stats['std_dev_e2e']}\")\n",
    "                print(f\"95th percentile of e2e time: {stats['percentile_95_e2e']}\")\n",
    "                print()\n",
    "    \n",
    "    # Create DataFrame for e2e_times\n",
    "    e2e_times_list = [entry['e2e_times'] for entry in data]\n",
    "    for i, e2e_times in enumerate(e2e_times_list):\n",
    "        df = pd.DataFrame({'e2e_times': e2e_times})\n",
    "        df['index'] = df.index\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))  # Make the chart wider\n",
    "        plt.plot(df['index'], df['e2e_times'])\n",
    "        truncated_name = file[:-4].split('_shape')[0]\n",
    "        plt.title(truncated_name, fontsize=10)  # Smaller font size for title\n",
    "        plt.xlabel('Index', fontsize=8)  # Smaller font size for x-axis label\n",
    "        plt.ylabel('e2e_times', fontsize=8)  # Smaller font size for y-axis label\n",
    "        plt.xticks(fontsize=8)  # Smaller font size for x-axis ticks\n",
    "        plt.yticks(fontsize=8)  # Smaller font size for y-axis ticks\n",
    "        plt.ylim(1, 20)  # Set y-axis limits\n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))  # Ensure y-axis has integer increments\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoai_benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
